{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insight Agent - Intelligent Business Analysis\n",
    "\n",
    "This notebook implements a sophisticated AI agent that analyzes text and extracts structured business insights, issues, and recommendations.\n",
    "\n",
    "## Capabilities\n",
    "\n",
    "- **Analyze** customer escalations, incidents, and business documents\n",
    "- **Extract** structured insights with severity classification\n",
    "- **Perform** root cause analysis\n",
    "- **Generate** actionable recommendations with priorities\n",
    "- **Provide** urgency scoring and escalation flags\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The agent uses:\n",
    "- **LangChain** for orchestration\n",
    "- **OpenAI GPT-4** for analysis\n",
    "- **Pydantic** for structured output validation\n",
    "- **JSON Schema** for consistent data formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, we'll install the required packages and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
      "  Downloading langsmith-0.4.43-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading ormsgpack-1.12.0-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.2 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading orjson-3.11.4-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Using cached tiktoken-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading langchain-1.0.7-py3-none-any.whl (93 kB)\n",
      "Downloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
      "Using cached pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.43-py3-none-any.whl (410 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
      "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp312-cp312-macosx_11_0_arm64.whl (319 kB)\n",
      "Using cached tiktoken-0.12.0-cp312-cp312-macosx_11_0_arm64.whl (994 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.4-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (243 kB)\n",
      "Downloading ormsgpack-1.12.0-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (369 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m640.4/640.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, xxhash, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, pyyaml, python-dotenv, ormsgpack, orjson, jsonpointer, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39/39\u001b[0m [langchain]39\u001b[0m [langchain]openai]int]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.11.12 charset_normalizer-3.4.4 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.12.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.7 langchain-core-1.0.5 langchain-openai-1.0.3 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 langsmith-0.4.43 openai-2.8.1 orjson-3.11.4 ormsgpack-1.12.0 pydantic-2.12.4 pydantic-core-2.41.5 python-dotenv-1.2.1 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.12.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "!pip install langchain langchain-openai langchain-core pydantic openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "# Pydantic for data validation\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain components\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure OpenAI API Key\n",
    "\n",
    "Set your OpenAI API key to enable the agent to communicate with GPT-4.\n",
    "\n",
    "**Options:**\n",
    "1. Set environment variable directly\n",
    "2. Load from `.env` file\n",
    "3. Set via system environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API Key found\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Set directly (not recommended for production)\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_API_KEY_HERE'\n",
    "\n",
    "# Option 2: Load from .env file (recommended)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is set\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    print(\"‚ö†Ô∏è  Warning: OPENAI_API_KEY not set. Please set it before running the analysis.\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API Key found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Data Models\n",
    "\n",
    "We use Pydantic models to ensure the AI output is structured and validated. This provides:\n",
    "- Type safety\n",
    "- Automatic validation\n",
    "- Clear schema definition\n",
    "- Easy JSON serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pydantic models defined successfully\n"
     ]
    }
   ],
   "source": [
    "class Issue(BaseModel):\n",
    "    \"\"\"Represents a single identified issue\"\"\"\n",
    "    description: str = Field(description=\"Clear, specific description of the issue\")\n",
    "    severity: str = Field(description=\"Severity: Low, Medium, High, or Critical\")\n",
    "    category: str = Field(description=\"Category: Technical, Business, Process, People, or Other\")\n",
    "    impact: str = Field(description=\"Describe the impact of this issue\")\n",
    "\n",
    "\n",
    "class Insight(BaseModel):\n",
    "    \"\"\"Represents a key insight or observation\"\"\"\n",
    "    insight: str = Field(description=\"The key insight or pattern identified\")\n",
    "    supporting_evidence: str = Field(description=\"Evidence from the text supporting this insight\")\n",
    "    confidence: str = Field(description=\"Confidence level: Low, Medium, or High\")\n",
    "    implications: str = Field(description=\"What this insight means for the business\")\n",
    "\n",
    "\n",
    "class RootCause(BaseModel):\n",
    "    \"\"\"Root cause analysis results\"\"\"\n",
    "    primary_cause: str = Field(description=\"The identified primary root cause\")\n",
    "    reasoning: str = Field(description=\"Detailed explanation of why this is the root cause\")\n",
    "    contributing_factors: List[str] = Field(description=\"Additional factors that contributed\")\n",
    "    evidence: List[str] = Field(description=\"Evidence supporting this root cause\")\n",
    "\n",
    "\n",
    "class Action(BaseModel):\n",
    "    \"\"\"Represents a single actionable recommendation\"\"\"\n",
    "    action: str = Field(description=\"Specific, actionable step\")\n",
    "    owner: str = Field(description=\"Suggested owner or department responsible\")\n",
    "    priority: str = Field(description=\"Priority: Low, Medium, High, or Urgent\")\n",
    "    timeline: str = Field(description=\"Suggested timeline for completion\")\n",
    "    expected_outcome: str = Field(description=\"What success looks like\")\n",
    "    dependencies: List[str] = Field(default_factory=list, description=\"Prerequisites or dependencies\")\n",
    "\n",
    "\n",
    "class InsightAgentOutput(BaseModel):\n",
    "    \"\"\"Complete output from the Insight Agent\"\"\"\n",
    "    executive_summary: str = Field(description=\"2-3 sentence executive summary\")\n",
    "    key_issues: List[Issue] = Field(description=\"All identified issues with severity\")\n",
    "    insights: List[Insight] = Field(description=\"Key insights and patterns\")\n",
    "    root_cause_analysis: Optional[RootCause] = Field(\n",
    "        default=None, \n",
    "        description=\"Root cause analysis if this is an incident or problem\"\n",
    "    )\n",
    "    recommended_actions: List[Action] = Field(description=\"Prioritized action items\")\n",
    "    urgency_score: int = Field(\n",
    "        ge=1, le=10,\n",
    "        description=\"Overall urgency from 1-10 based on impact and severity\"\n",
    "    )\n",
    "    requires_escalation: bool = Field(description=\"Whether this requires management escalation\")\n",
    "    estimated_impact: str = Field(description=\"Estimated business impact: Low, Medium, High, or Critical\")\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict, description=\"Additional metadata\")\n",
    "\n",
    "print(\"‚úÖ Pydantic models defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the Insight Agent\n",
    "\n",
    "The `SimpleInsightAgent` class encapsulates the AI analysis logic. It:\n",
    "\n",
    "1. **Creates a structured prompt** with detailed analysis requirements\n",
    "2. **Chains together** LangChain components (prompt ‚Üí LLM ‚Üí parser)\n",
    "3. **Validates output** using Pydantic models\n",
    "4. **Adds metadata** for tracking and auditing\n",
    "\n",
    "### Key Design Decision\n",
    "\n",
    "We use `StrOutputParser()` before `PydanticOutputParser()` to extract the text content from the LLM response before parsing it as JSON. This prevents type errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SimpleInsightAgent class defined\n"
     ]
    }
   ],
   "source": [
    "class SimpleInsightAgent:\n",
    "    \"\"\"\n",
    "    AI-powered insight agent that analyzes text and extracts structured insights.\n",
    "    \n",
    "    Features:\n",
    "    - Executive summary generation\n",
    "    - Issue identification with severity classification\n",
    "    - Pattern and insight detection\n",
    "    - Root cause analysis\n",
    "    - Actionable recommendation generation\n",
    "    - Urgency scoring and escalation flags\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        \"\"\"\n",
    "        Initialize the agent with an LLM.\n",
    "        \n",
    "        Args:\n",
    "            llm: LangChain LLM instance (e.g., ChatOpenAI)\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.parser = PydanticOutputParser(pydantic_object=InsightAgentOutput)\n",
    "        \n",
    "        # Create prompt template with detailed analysis instructions\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"human\", \"\"\"\n",
    "            You are an expert business analyst specializing in operational analysis and risk assessment.\n",
    "\n",
    "            Your task is to perform a comprehensive analysis of the following text and extract actionable insights.\n",
    "\n",
    "            TEXT TO ANALYZE:\n",
    "            {text}\n",
    "\n",
    "            ANALYSIS REQUIREMENTS:\n",
    "\n",
    "            1. EXECUTIVE SUMMARY (2-3 sentences)\n",
    "               - What is this about?\n",
    "               - What is the main concern?\n",
    "               - What is at stake?\n",
    "\n",
    "            2. KEY ISSUES\n",
    "               - Identify ALL distinct issues mentioned or implied\n",
    "               - Classify severity: Low, Medium, High, or Critical\n",
    "               - Categorize: Technical, Business, Process, People, or Other\n",
    "               - Describe impact for each issue\n",
    "\n",
    "            3. INSIGHTS & PATTERNS\n",
    "               - What patterns do you observe?\n",
    "               - What are the underlying themes?\n",
    "               - What implications does this have?\n",
    "               - Provide supporting evidence from the text\n",
    "               - Indicate confidence level for each insight\n",
    "\n",
    "            4. ROOT CAUSE ANALYSIS (if applicable)\n",
    "               - If this describes a problem or incident, identify the PRIMARY root cause\n",
    "               - Explain your reasoning with evidence\n",
    "               - List contributing factors\n",
    "               - If root cause is unclear, acknowledge this\n",
    "\n",
    "            5. RECOMMENDED ACTIONS\n",
    "               - Provide specific, actionable steps\n",
    "               - Assign suggested owners (departments or roles)\n",
    "               - Set priorities: Low, Medium, High, or Urgent\n",
    "               - Suggest timelines\n",
    "               - Describe expected outcomes\n",
    "               - Note any dependencies\n",
    "\n",
    "            6. URGENCY & ESCALATION\n",
    "               - Assign urgency score (1-10) based on:\n",
    "                 * Severity of issues\n",
    "                 * Business impact\n",
    "                 * Time sensitivity\n",
    "               - Determine if escalation to management is needed\n",
    "               - Estimate overall business impact: Low, Medium, High, or Critical\n",
    "\n",
    "            IMPORTANT GUIDELINES:\n",
    "            - Base ALL analysis on information in the text\n",
    "            - Be specific, not generic\n",
    "            - Prioritize actionability over description\n",
    "            - If information is missing, acknowledge it\n",
    "            - Use business language, not technical jargon\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output ONLY valid JSON. No additional text.\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Build the processing chain\n",
    "        # StrOutputParser extracts text content from LLM message\n",
    "        # PydanticOutputParser then parses JSON into structured model\n",
    "        self.chain = (\n",
    "            self.prompt \n",
    "            | self.llm \n",
    "            | StrOutputParser()  # Extract text content\n",
    "            | self.parser         # Parse JSON into Pydantic model\n",
    "        )\n",
    "    \n",
    "    def analyze(self, text: str) -> InsightAgentOutput:\n",
    "        \"\"\"\n",
    "        Analyze text and return structured insights.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to analyze (customer feedback, incident report, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            InsightAgentOutput: Structured analysis results\n",
    "        \"\"\"\n",
    "        result = self.chain.invoke({\n",
    "            \"text\": text,\n",
    "            \"format_instructions\": self.parser.get_format_instructions()\n",
    "        })\n",
    "        \n",
    "        # Add metadata for tracking\n",
    "        result.metadata[\"analysis_date\"] = datetime.now().isoformat()\n",
    "        result.metadata[\"source\"] = \"simple_agent\"\n",
    "        result.metadata[\"text_length\"] = len(text)\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"‚úÖ SimpleInsightAgent class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Display Helper Function\n",
    "\n",
    "This function provides a formatted, readable output of the analysis results with color-coded emojis for easy scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Display helper function defined\n"
     ]
    }
   ],
   "source": [
    "def display_insight_analysis(result: InsightAgentOutput, title: str = \"INSIGHT ANALYSIS\"):\n",
    "    \"\"\"\n",
    "    Pretty print the analysis results with formatting and emojis.\n",
    "    \n",
    "    Args:\n",
    "        result: InsightAgentOutput from the agent\n",
    "        title: Title for the analysis display\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\" {title}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Executive Summary\n",
    "    print(\"\\nüìä EXECUTIVE SUMMARY\")\n",
    "    print(\"-\" * 80)\n",
    "    print(result.executive_summary)\n",
    "    \n",
    "    # Urgency & Impact\n",
    "    print(f\"\\n‚ö†Ô∏è  URGENCY SCORE: {result.urgency_score}/10\")\n",
    "    print(f\"üìà ESTIMATED IMPACT: {result.estimated_impact}\")\n",
    "    print(f\"üö® REQUIRES ESCALATION: {'YES' if result.requires_escalation else 'NO'}\")\n",
    "    \n",
    "    # Key Issues\n",
    "    print(f\"\\nüîç KEY ISSUES ({len(result.key_issues)} identified)\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, issue in enumerate(result.key_issues, 1):\n",
    "        severity_emoji = {\n",
    "            \"Critical\": \"üî¥\",\n",
    "            \"High\": \"üü†\",\n",
    "            \"Medium\": \"üü°\",\n",
    "            \"Low\": \"üü¢\"\n",
    "        }.get(issue.severity, \"‚ö™\")\n",
    "        \n",
    "        print(f\"\\n{i}. {severity_emoji} {issue.severity.upper()} - {issue.category}\")\n",
    "        print(f\"   Description: {issue.description}\")\n",
    "        print(f\"   Impact: {issue.impact}\")\n",
    "    \n",
    "    # Insights\n",
    "    print(f\"\\nüí° KEY INSIGHTS ({len(result.insights)} identified)\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, insight in enumerate(result.insights, 1):\n",
    "        confidence_emoji = {\n",
    "            \"High\": \"‚úÖ\",\n",
    "            \"Medium\": \"‚ö†Ô∏è\",\n",
    "            \"Low\": \"‚ùì\"\n",
    "        }.get(insight.confidence, \"‚ö™\")\n",
    "        \n",
    "        print(f\"\\n{i}. {confidence_emoji} {insight.insight}\")\n",
    "        print(f\"   Confidence: {insight.confidence}\")\n",
    "        print(f\"   Evidence: {insight.supporting_evidence}\")\n",
    "        print(f\"   Implications: {insight.implications}\")\n",
    "    \n",
    "    # Root Cause Analysis\n",
    "    if result.root_cause_analysis:\n",
    "        print(\"\\nüéØ ROOT CAUSE ANALYSIS\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Primary Cause: {result.root_cause_analysis.primary_cause}\")\n",
    "        print(f\"\\nReasoning: {result.root_cause_analysis.reasoning}\")\n",
    "        \n",
    "        if result.root_cause_analysis.contributing_factors:\n",
    "            print(\"\\nContributing Factors:\")\n",
    "            for factor in result.root_cause_analysis.contributing_factors:\n",
    "                print(f\"  ‚Ä¢ {factor}\")\n",
    "        \n",
    "        if result.root_cause_analysis.evidence:\n",
    "            print(\"\\nSupporting Evidence:\")\n",
    "            for evidence in result.root_cause_analysis.evidence:\n",
    "                print(f\"  ‚Ä¢ {evidence}\")\n",
    "    \n",
    "    # Recommended Actions\n",
    "    print(f\"\\n‚úÖ RECOMMENDED ACTIONS ({len(result.recommended_actions)} actions)\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, action in enumerate(result.recommended_actions, 1):\n",
    "        priority_emoji = {\n",
    "            \"Urgent\": \"üî¥\",\n",
    "            \"High\": \"üü†\",\n",
    "            \"Medium\": \"üü°\",\n",
    "            \"Low\": \"üü¢\"\n",
    "        }.get(action.priority, \"‚ö™\")\n",
    "        \n",
    "        print(f\"\\n{i}. {priority_emoji} [{action.priority}] {action.action}\")\n",
    "        print(f\"   Owner: {action.owner}\")\n",
    "        print(f\"   Timeline: {action.timeline}\")\n",
    "        print(f\"   Expected Outcome: {action.expected_outcome}\")\n",
    "        \n",
    "        if action.dependencies:\n",
    "            print(f\"   Dependencies: {', '.join(action.dependencies)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"‚úÖ Display helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize the Agent\n",
    "\n",
    "Create an instance of the agent with GPT-4 configured for optimal analysis performance.\n",
    "\n",
    "**Configuration:**\n",
    "- **Model:** GPT-4o (balanced performance and cost)\n",
    "- **Temperature:** 0.3 (lower = more consistent)\n",
    "- **Response Format:** JSON mode (ensures valid JSON output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Insight Agent initialized and ready\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM with appropriate settings\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",  # Options: \"gpt-4o\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"\n",
    "    temperature=0.3,  # Lower temperature for more consistent analysis\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}}  # Ensure JSON output\n",
    ")\n",
    "\n",
    "# Create the agent\n",
    "simple_agent = SimpleInsightAgent(llm)\n",
    "\n",
    "print(\"‚úÖ Insight Agent initialized and ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Case 1: Customer Escalation Analysis\n",
    "\n",
    "This example analyzes a critical customer escalation from a high-value enterprise account experiencing service issues.\n",
    "\n",
    "**Scenario:** Fortune 500 customer threatening to cancel a $2.4M contract due to:\n",
    "- Multiple service outages\n",
    "- Poor support response times\n",
    "- Undelivered features\n",
    "- Financial and reputational damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing customer escalation...\n",
      "\n",
      "================================================================================\n",
      " CUSTOMER ESCALATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä EXECUTIVE SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "The text is an urgent escalation from TechCorp Global regarding severe reliability and support issues with the platform. The main concern is the repeated system outages and inadequate support response, which threaten a significant revenue source and reference account. At stake is the potential loss of a $2.4M contract, damage to reputation, and the risk of public exposure of the issues.\n",
      "\n",
      "‚ö†Ô∏è  URGENCY SCORE: 10/10\n",
      "üìà ESTIMATED IMPACT: Critical\n",
      "üö® REQUIRES ESCALATION: YES\n",
      "\n",
      "üîç KEY ISSUES (5 identified)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. üî¥ CRITICAL - Technical\n",
      "   Description: Four complete system outages in the last 30 days.\n",
      "   Impact: Complete loss of platform access, data sync failures, and significant financial and reputational damage.\n",
      "\n",
      "2. üü† HIGH - Process\n",
      "   Description: No proactive communication about outages.\n",
      "   Impact: Increased customer frustration and lack of trust in the service provider.\n",
      "\n",
      "3. üü† HIGH - Process\n",
      "   Description: Support response time averages 48-72 hours.\n",
      "   Impact: Delayed resolution of critical issues, leading to prolonged downtime and customer dissatisfaction.\n",
      "\n",
      "4. üü† HIGH - Technical\n",
      "   Description: Vague and unhelpful root cause analyses.\n",
      "   Impact: Inability to prevent future incidents and loss of customer confidence.\n",
      "\n",
      "5. üü° MEDIUM - Business\n",
      "   Description: Undelivered features promised during the sales cycle.\n",
      "   Impact: Erosion of trust and potential breach of contract terms.\n",
      "\n",
      "üí° KEY INSIGHTS (2 identified)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. ‚úÖ Repeated outages and poor support response indicate systemic issues.\n",
      "   Confidence: High\n",
      "   Evidence: Four outages in 30 days, long support response times, and vague root cause analyses.\n",
      "   Implications: The company may face significant financial and reputational risks if these issues are not addressed promptly.\n",
      "\n",
      "2. ‚úÖ Lack of proactive communication exacerbates customer dissatisfaction.\n",
      "   Confidence: High\n",
      "   Evidence: No proactive communication about outages reported by TechCorp.\n",
      "   Implications: Improving communication could mitigate some customer dissatisfaction and restore trust.\n",
      "\n",
      "üéØ ROOT CAUSE ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Primary Cause: Systemic reliability and support process failures.\n",
      "\n",
      "Reasoning: The frequency of outages and delayed support response suggest underlying systemic issues rather than isolated incidents.\n",
      "\n",
      "Contributing Factors:\n",
      "  ‚Ä¢ Inadequate infrastructure or system design\n",
      "  ‚Ä¢ Insufficient support staffing or training\n",
      "  ‚Ä¢ Lack of effective communication protocols\n",
      "\n",
      "Supporting Evidence:\n",
      "  ‚Ä¢ Four complete outages in 30 days\n",
      "  ‚Ä¢ Support response time averages 48-72 hours\n",
      "  ‚Ä¢ Vague root cause analyses\n",
      "\n",
      "‚úÖ RECOMMENDED ACTIONS (5 actions)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. üî¥ [Urgent] Conduct a comprehensive technical audit to identify and address system vulnerabilities.\n",
      "   Owner: IT Department\n",
      "   Timeline: Within 7 days\n",
      "   Expected Outcome: Improved system reliability and reduced risk of future outages.\n",
      "\n",
      "2. üü† [High] Implement a proactive communication strategy for outage notifications.\n",
      "   Owner: Customer Support\n",
      "   Timeline: Within 3 days\n",
      "   Expected Outcome: Enhanced customer trust and satisfaction.\n",
      "\n",
      "3. üü† [High] Review and optimize support processes to reduce response times.\n",
      "   Owner: Customer Support\n",
      "   Timeline: Within 14 days\n",
      "   Expected Outcome: Faster issue resolution and improved customer satisfaction.\n",
      "\n",
      "4. üî¥ [Urgent] Deliver a detailed root cause analysis for each outage with actionable prevention plans.\n",
      "   Owner: IT Department\n",
      "   Timeline: Within 24 hours\n",
      "   Expected Outcome: Clear understanding of issues and prevention of future occurrences.\n",
      "\n",
      "5. üî¥ [Urgent] Schedule an executive-level meeting with TechCorp to address concerns and outline improvement plans.\n",
      "   Owner: VP of Customer Success\n",
      "   Timeline: Within 24 hours\n",
      "   Expected Outcome: Reassurance of commitment to resolving issues and retention of the client.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "customer_escalation = \"\"\"\n",
    "URGENT ESCALATION - Enterprise Account\n",
    "Customer: TechCorp Global (Account #A-7845)\n",
    "Date: January 20, 2024\n",
    "Reported by: Jennifer Martinez, CTO\n",
    "\n",
    "We are writing to formally escalate serious concerns about your platform's reliability and support.\n",
    "Over the past 30 days, we have experienced FOUR complete system outages affecting our entire\n",
    "operations. Each incident has resulted in:\n",
    "\n",
    "1. Complete loss of platform access (longest: 6 hours)\n",
    "2. Data sync failures causing reporting inconsistencies\n",
    "3. Lost productivity estimated at $75,000 per incident\n",
    "4. Damage to our reputation with our own customers\n",
    "\n",
    "What's particularly concerning:\n",
    "- We receive no proactive communication about outages\n",
    "- Support response time averages 48-72 hours\n",
    "- Root cause analyses are vague and unhelpful\n",
    "- Promised features from our sales cycle remain undelivered\n",
    "\n",
    "TechCorp represents 18% of our annual revenue ($2.4M contract) and serves as a reference account\n",
    "for our industry. We are a Fortune 500 company with strict SLA requirements.\n",
    "\n",
    "We require within 24 hours:\n",
    "1. Detailed root cause analysis for ALL four outages\n",
    "2. Concrete prevention plan with measurable milestones\n",
    "3. Service credits totaling $300,000\n",
    "4. Executive-level meeting with your VP of Customer Success\n",
    "5. Assigned dedicated support engineer\n",
    "\n",
    "Without immediate action, we will:\n",
    "- Invoke the termination clause in our contract\n",
    "- Explore alternative vendors (RFP already in progress)\n",
    "- Share our experience publicly in industry forums\n",
    "\n",
    "Our renewal is in 90 days. We need to see dramatic improvement or we will not renew.\n",
    "\n",
    "Jennifer Martinez\n",
    "Chief Technology Officer\n",
    "TechCorp Global\n",
    "\"\"\"\n",
    "\n",
    "print(\"Analyzing customer escalation...\\n\")\n",
    "result1 = simple_agent.analyze(customer_escalation)\n",
    "display_insight_analysis(result1, \"CUSTOMER ESCALATION ANALYSIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Analysis to JSON\n",
    "\n",
    "Export the structured results for integration with other systems or databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "JSON OUTPUT (for API/Database integration):\n",
      "================================================================================\n",
      "{\n",
      "  \"executive_summary\": \"The text is an urgent escalation from TechCorp Global regarding severe reliability and support issues with the platform. The main concern is the repeated system outages and inadequate support response, which threaten a significant revenue source and reference account. At stake is the potential loss of a $2.4M contract, damage to reputation, and the risk of public exposure of the issues.\",\n",
      "  \"key_issues\": [\n",
      "    {\n",
      "      \"description\": \"Four complete system outages in the last 30 days.\",\n",
      "      \"severity\": \"Critical\",\n",
      "      \"category\": \"Technical\",\n",
      "      \"impact\": \"Complete loss of platform access, data sync failures, and significant financial and reputational damage.\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"No proactive communication about outages.\",\n",
      "      \"severity\": \"High\",\n",
      "      \"category\": \"Process\",\n",
      "      \"impact\": \"Increased customer frustration and lack of trust in the service provider.\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Support response time averages 48-72 ho...\n",
      "[truncated]\n",
      "\n",
      "Full JSON length: 4855 characters\n",
      "\n",
      "‚úÖ Full analysis saved to: customer_escalation_analysis.json\n"
     ]
    }
   ],
   "source": [
    "# Convert to dictionary and save as JSON\n",
    "result_dict = result1.model_dump()\n",
    "result_json = json.dumps(result_dict, indent=2)\n",
    "\n",
    "# Display preview\n",
    "print(\"=\" * 80)\n",
    "print(\"JSON OUTPUT (for API/Database integration):\")\n",
    "print(\"=\" * 80)\n",
    "if len(result_json) > 1000:\n",
    "    print(result_json[:1000] + \"...\\n[truncated]\")\n",
    "    print(f\"\\nFull JSON length: {len(result_json)} characters\")\n",
    "else:\n",
    "    print(result_json)\n",
    "\n",
    "# Save to file\n",
    "output_file = \"customer_escalation_analysis.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(result_dict, f, indent=2)\n",
    "print(f\"\\n‚úÖ Full analysis saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Case 2: Production Incident Report\n",
    "\n",
    "This example analyzes a critical production outage affecting payment processing.\n",
    "\n",
    "**Scenario:** 3.8-hour outage causing:\n",
    "- $420,000 revenue loss\n",
    "- 15,000+ support tickets\n",
    "- Negative social media impact\n",
    "- Database connection pool exhaustion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing production incident...\n",
      "\n",
      "================================================================================\n",
      " PRODUCTION INCIDENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä EXECUTIVE SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "The incident report describes a critical production outage affecting payment processing and user authentication services, resulting in significant revenue loss and negative customer sentiment. The main concern is the unoptimized query from a new feature deployment that led to a database connection pool exhaustion. At stake is the company's financial performance and customer trust.\n",
      "\n",
      "‚ö†Ô∏è  URGENCY SCORE: 9/10\n",
      "üìà ESTIMATED IMPACT: Critical\n",
      "üö® REQUIRES ESCALATION: YES\n",
      "\n",
      "üîç KEY ISSUES (6 identified)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. üî¥ CRITICAL - Technical\n",
      "   Description: Database connection pool exhaustion due to unoptimized query.\n",
      "   Impact: Caused 100% failure of payment transactions and significant revenue loss.\n",
      "\n",
      "2. üü† HIGH - Technical\n",
      "   Description: Runaway query from new feature deployment.\n",
      "   Impact: Led to the outage and was not caught in staging due to insufficient data volume.\n",
      "\n",
      "3. üü† HIGH - Process\n",
      "   Description: Failed rollback due to migration dependencies.\n",
      "   Impact: Prolonged the outage as rollback procedures were ineffective.\n",
      "\n",
      "4. üü° MEDIUM - Technical\n",
      "   Description: Insufficient staging environment.\n",
      "   Impact: Failed to replicate production load, missing the issue during testing.\n",
      "\n",
      "5. üü† HIGH - Technical\n",
      "   Description: No query performance monitoring in place.\n",
      "   Impact: Delayed identification and resolution of the performance issue.\n",
      "\n",
      "6. üü° MEDIUM - Process\n",
      "   Description: Lack of gradual rollout strategy for new features.\n",
      "   Impact: Increased risk of widespread impact from new deployments.\n",
      "\n",
      "üí° KEY INSIGHTS (2 identified)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. ‚úÖ The staging environment is not reflective of production conditions.\n",
      "   Confidence: High\n",
      "   Evidence: Load testing in staging missed the issue because test data volume was only 1% of production.\n",
      "   Implications: Future deployments may continue to fail if staging environments are not improved.\n",
      "\n",
      "2. ‚úÖ Lack of monitoring and rollback strategies exacerbated the outage.\n",
      "   Confidence: High\n",
      "   Evidence: No query performance monitoring in place and rollback procedures not tested.\n",
      "   Implications: Increases the risk of prolonged outages and impacts on business operations.\n",
      "\n",
      "üéØ ROOT CAUSE ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Primary Cause: Unoptimized query from new recommendation engine deployment.\n",
      "\n",
      "Reasoning: The new feature deployment contained an unoptimized query that created an N+1 problem, exhausting the database connection pool.\n",
      "\n",
      "Contributing Factors:\n",
      "  ‚Ä¢ Insufficient staging environment\n",
      "  ‚Ä¢ No query performance monitoring\n",
      "  ‚Ä¢ Rollback procedures not tested\n",
      "  ‚Ä¢ No gradual rollout strategy\n",
      "\n",
      "Supporting Evidence:\n",
      "  ‚Ä¢ Database connection pool exhausted, services start failing\n",
      "  ‚Ä¢ New recommendation engine deployed contained unoptimized query\n",
      "\n",
      "‚úÖ RECOMMENDED ACTIONS (4 actions)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. üü† [High] Enhance staging environment to better simulate production load.\n",
      "   Owner: IT Infrastructure\n",
      "   Timeline: 1 month\n",
      "   Expected Outcome: Improved detection of issues before production deployment.\n",
      "\n",
      "2. üî¥ [Urgent] Implement query performance monitoring tools.\n",
      "   Owner: Database Administration\n",
      "   Timeline: 2 weeks\n",
      "   Expected Outcome: Faster identification and resolution of performance issues.\n",
      "\n",
      "3. üü† [High] Develop and test rollback procedures for all deployments.\n",
      "   Owner: DevOps\n",
      "   Timeline: 1 month\n",
      "   Expected Outcome: Reduced downtime in case of deployment failures.\n",
      "\n",
      "4. üü° [Medium] Adopt a gradual rollout strategy for new features.\n",
      "   Owner: Product Management\n",
      "   Timeline: 2 months\n",
      "   Expected Outcome: Minimized risk of widespread impact from new deployments.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "production_incident = \"\"\"\n",
    "INCIDENT REPORT - P1 Production Outage\n",
    "Incident ID: INC-2024-0156\n",
    "Date: January 18, 2024, 14:23 UTC\n",
    "Duration: 3 hours 47 minutes\n",
    "Affected Services: Payment Processing, User Authentication\n",
    "\n",
    "IMPACT:\n",
    "- 100% of payment transactions failed during outage window\n",
    "- Estimated revenue loss: $420,000\n",
    "- 15,000+ customer support tickets created\n",
    "- Social media sentiment turned negative (-67% shift)\n",
    "\n",
    "TIMELINE:\n",
    "14:23 - Database connection pool exhausted, services start failing\n",
    "14:45 - PagerDuty alerts trigger, on-call engineer engaged\n",
    "15:12 - Issue identified as runaway query from new feature deployment\n",
    "15:30 - Attempted rollback failed due to migration dependencies\n",
    "16:45 - Manual database cleanup initiated\n",
    "18:10 - Services fully restored\n",
    "\n",
    "ROOT CAUSE:\n",
    "New recommendation engine deployed at 13:00 contained unoptimized query that \n",
    "created N+1 problem. Load testing in staging missed this because test data \n",
    "volume was only 1% of production.\n",
    "\n",
    "CONTRIBUTING FACTORS:\n",
    "- Insufficient staging environment\n",
    "- No query performance monitoring in place\n",
    "- Rollback procedures not tested\n",
    "- No gradual rollout strategy for new features\n",
    "\"\"\"\n",
    "\n",
    "print(\"Analyzing production incident...\\n\")\n",
    "result2 = simple_agent.analyze(production_incident)\n",
    "display_insight_analysis(result2, \"PRODUCTION INCIDENT ANALYSIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Case 3: Employee Feedback Analysis\n",
    "\n",
    "This example analyzes quarterly employee survey results showing concerning trends.\n",
    "\n",
    "**Scenario:** Engineering department survey reveals:\n",
    "- Declining work-life balance scores\n",
    "- Burnout from context switching\n",
    "- Frequent scope changes disrupting sprints\n",
    "- Recent departures citing unsustainable pace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_feedback = \"\"\"\n",
    "QUARTERLY SURVEY - Engineering Department Results\n",
    "Q4 2023 - 127 Responses (85% participation rate)\n",
    "\n",
    "SATISFACTION SCORES (1-10 scale):\n",
    "- Work-life balance: 4.2 (down from 7.1 in Q3)\n",
    "- Management communication: 5.8 (down from 6.9)\n",
    "- Career growth opportunities: 6.1 (stable)\n",
    "- Technical challenges: 8.2 (up from 7.8)\n",
    "- Team collaboration: 7.9 (stable)\n",
    "\n",
    "RECURRING THEMES FROM OPEN RESPONSES:\n",
    "\n",
    "\"The constant context switching between projects is burning everyone out. \n",
    "I'm working on 4 different initiatives simultaneously.\" - 23 similar comments\n",
    "\n",
    "\"We keep getting urgent requests from sales that derail our sprint plans. \n",
    "There's no buffer for unplanned work.\" - 18 similar comments\n",
    "\n",
    "\"I love the technical problems we're solving, but the pace is unsustainable. \n",
    "Three teammates quit in the last month citing burnout.\" - 31 similar comments\n",
    "\n",
    "\"Leadership keeps saying 'work-life balance is important' but then expects \n",
    "us to deliver impossible timelines.\" - 15 similar comments\n",
    "\n",
    "POSITIVE FEEDBACK:\n",
    "\"The new tech stack is great to work with\" - 42 mentions\n",
    "\"Team members are talented and supportive\" - 38 mentions\n",
    "\"Product vision is exciting\" - 27 mentions\n",
    "\"\"\"\n",
    "\n",
    "print(\"Analyzing employee feedback...\\n\")\n",
    "result3 = simple_agent.analyze(employee_feedback)\n",
    "display_insight_analysis(result3, \"EMPLOYEE FEEDBACK ANALYSIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Utility Functions\n",
    "\n",
    "Helper functions to filter and extract specific types of information from analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critical_issues(result: InsightAgentOutput) -> List[Issue]:\n",
    "    \"\"\"Extract only critical severity issues\"\"\"\n",
    "    return [issue for issue in result.key_issues if issue.severity == \"Critical\"]\n",
    "\n",
    "def get_urgent_actions(result: InsightAgentOutput) -> List[Action]:\n",
    "    \"\"\"Extract only urgent priority actions\"\"\"\n",
    "    return [action for action in result.recommended_actions if action.priority == \"Urgent\"]\n",
    "\n",
    "def get_high_confidence_insights(result: InsightAgentOutput) -> List[Insight]:\n",
    "    \"\"\"Extract only high confidence insights\"\"\"\n",
    "    return [insight for insight in result.insights if insight.confidence == \"High\"]\n",
    "\n",
    "# Example usage\n",
    "print(\"=\" * 80)\n",
    "print(\"FILTERED ANALYSIS - Customer Escalation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "critical_issues = get_critical_issues(result1)\n",
    "print(f\"\\nüî¥ CRITICAL ISSUES ONLY ({len(critical_issues)}):\")\n",
    "for i, issue in enumerate(critical_issues, 1):\n",
    "    print(f\"{i}. {issue.description}\")\n",
    "\n",
    "urgent_actions = get_urgent_actions(result1)\n",
    "print(f\"\\nüî¥ URGENT ACTIONS ONLY ({len(urgent_actions)}):\")\n",
    "for i, action in enumerate(urgent_actions, 1):\n",
    "    print(f\"{i}. {action.action} (Owner: {action.owner})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Batch Processing\n",
    "\n",
    "Process multiple documents in a single run for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_analyze(texts: List[str], descriptions: List[str]) -> List[InsightAgentOutput]:\n",
    "    \"\"\"\n",
    "    Analyze multiple texts in batch.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of texts to analyze\n",
    "        descriptions: List of descriptions for each text\n",
    "        \n",
    "    Returns:\n",
    "        List of InsightAgentOutput results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, (text, desc) in enumerate(zip(texts, descriptions), 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing {i}/{len(texts)}: {desc}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        result = simple_agent.analyze(text)\n",
    "        results.append(result)\n",
    "        print(f\"‚úÖ Completed - Urgency: {result.urgency_score}/10, Issues: {len(result.key_issues)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Uncomment to run batch processing\n",
    "# batch_texts = [customer_escalation, production_incident, employee_feedback]\n",
    "# batch_descriptions = [\"Customer Escalation\", \"Production Incident\", \"Employee Feedback\"]\n",
    "# batch_results = batch_analyze(batch_texts, batch_descriptions)\n",
    "\n",
    "print(\"‚úÖ Batch processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Functions\n",
    "\n",
    "Export analysis results to different formats for reporting and integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(result: InsightAgentOutput, filename: str):\n",
    "    \"\"\"Export issues and actions to CSV format\"\"\"\n",
    "    import csv\n",
    "    \n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # Write issues\n",
    "        writer.writerow(['Type', 'Severity/Priority', 'Category/Owner', 'Description/Action', 'Impact/Outcome'])\n",
    "        writer.writerow([])\n",
    "        writer.writerow(['ISSUES'])\n",
    "        for issue in result.key_issues:\n",
    "            writer.writerow(['Issue', issue.severity, issue.category, issue.description, issue.impact])\n",
    "        \n",
    "        writer.writerow([])\n",
    "        writer.writerow(['ACTIONS'])\n",
    "        for action in result.recommended_actions:\n",
    "            writer.writerow(['Action', action.priority, action.owner, action.action, action.expected_outcome])\n",
    "    \n",
    "    print(f\"‚úÖ Exported to CSV: {filename}\")\n",
    "\n",
    "\n",
    "def export_to_markdown(result: InsightAgentOutput, filename: str):\n",
    "    \"\"\"Export analysis to Markdown format\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"# Insight Analysis Report\\n\\n\")\n",
    "        f.write(f\"**Analysis Date:** {result.metadata.get('analysis_date', 'N/A')}\\n\\n\")\n",
    "        f.write(f\"**Urgency Score:** {result.urgency_score}/10\\n\\n\")\n",
    "        f.write(f\"**Estimated Impact:** {result.estimated_impact}\\n\\n\")\n",
    "        f.write(f\"## Executive Summary\\n\\n{result.executive_summary}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"## Key Issues ({len(result.key_issues)})\\n\\n\")\n",
    "        for i, issue in enumerate(result.key_issues, 1):\n",
    "            f.write(f\"### {i}. [{issue.severity}] {issue.category}\\n\")\n",
    "            f.write(f\"**Description:** {issue.description}\\n\\n\")\n",
    "            f.write(f\"**Impact:** {issue.impact}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"## Recommended Actions ({len(result.recommended_actions)})\\n\\n\")\n",
    "        for i, action in enumerate(result.recommended_actions, 1):\n",
    "            f.write(f\"### {i}. [{action.priority}] {action.action}\\n\")\n",
    "            f.write(f\"- **Owner:** {action.owner}\\n\")\n",
    "            f.write(f\"- **Timeline:** {action.timeline}\\n\")\n",
    "            f.write(f\"- **Expected Outcome:** {action.expected_outcome}\\n\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Exported to Markdown: {filename}\")\n",
    "\n",
    "# Example exports\n",
    "export_to_csv(result1, \"customer_escalation_analysis.csv\")\n",
    "export_to_markdown(result1, \"customer_escalation_analysis.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary Statistics\n",
    "\n",
    "Generate aggregate statistics across multiple analyses for trending and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_stats(results: List[InsightAgentOutput]) -> Dict[str, Any]:\n",
    "    \"\"\"Generate aggregate statistics across multiple analyses\"\"\"\n",
    "    stats = {\n",
    "        \"total_analyses\": len(results),\n",
    "        \"avg_urgency_score\": sum(r.urgency_score for r in results) / len(results),\n",
    "        \"total_issues\": sum(len(r.key_issues) for r in results),\n",
    "        \"total_actions\": sum(len(r.recommended_actions) for r in results),\n",
    "        \"escalation_required_count\": sum(1 for r in results if r.requires_escalation),\n",
    "        \"impact_distribution\": {},\n",
    "        \"severity_distribution\": {}\n",
    "    }\n",
    "    \n",
    "    # Impact distribution\n",
    "    for result in results:\n",
    "        impact = result.estimated_impact\n",
    "        stats[\"impact_distribution\"][impact] = stats[\"impact_distribution\"].get(impact, 0) + 1\n",
    "    \n",
    "    # Severity distribution\n",
    "    for result in results:\n",
    "        for issue in result.key_issues:\n",
    "            severity = issue.severity\n",
    "            stats[\"severity_distribution\"][severity] = stats[\"severity_distribution\"].get(severity, 0) + 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Example with our test cases\n",
    "all_results = [result1, result2, result3]\n",
    "summary = generate_summary_stats(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS - All Analyses\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. How To Use\n",
    "\n",
    "### Quick Usage\n",
    "\n",
    "```python\n",
    "# Analyze any text\n",
    "result = simple_agent.analyze(your_text)\n",
    "\n",
    "# Display formatted output\n",
    "display_insight_analysis(result)\n",
    "\n",
    "# Export to different formats\n",
    "export_to_json(result, \"analysis.json\")\n",
    "export_to_csv(result, \"analysis.csv\")\n",
    "export_to_markdown(result, \"analysis.md\")\n",
    "\n",
    "# Filter specific information\n",
    "critical_issues = get_critical_issues(result)\n",
    "urgent_actions = get_urgent_actions(result)\n",
    "```\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "1. **Customer Support** - Analyze escalations and prioritize responses\n",
    "2. **Incident Management** - Perform root cause analysis on outages\n",
    "3. **HR Analytics** - Extract insights from employee feedback\n",
    "4. **Product Management** - Analyze user feedback and feature requests\n",
    "5. **Risk Assessment** - Identify and categorize business risks\n",
    "\n",
    "### Customization\n",
    "\n",
    "- Modify the prompt in `SimpleInsightAgent.__init__()` for domain-specific analysis\n",
    "- Adjust Pydantic models to capture additional fields\n",
    "- Change LLM temperature for more creative vs. deterministic analysis\n",
    "- Add custom filtering and export functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
