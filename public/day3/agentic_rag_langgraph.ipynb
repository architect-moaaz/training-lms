{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI RAG Agent with FAISS and LangGraph\n",
    "\n",
    "**Goal:** Fully autonomous AI agent system that uses LLMs and vector search to assign drivers optimally.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "This notebook implements a **fully agentic** multi-agent system where:\n",
    "- Each agent uses **LLMs** for reasoning and decision-making\n",
    "- **FAISS vector database** stores driver and load embeddings\n",
    "- Agents can **query** the vector store semantically\n",
    "- Agents have **tools** to retrieve and analyze data\n",
    "- **Autonomous** decision-making with explanations\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Traditional manual driver assignment leads to:\n",
    "- Manual effort and delays\n",
    "- Outdated HOS data\n",
    "- Driver-load mismatches\n",
    "- Compliance risks\n",
    "\n",
    "## Solution: Agentic AI with Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install langgraph langchain langchain-openai langchain-community faiss-cpu openai tiktoken pandas matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Optional, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure LLM and Embeddings\n",
    "\n",
    "Set your OpenAI API key to enable the agentic system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "# Option 1: Set environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Option 2: Load from .env file\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# Check if API key is set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è  WARNING: OPENAI_API_KEY not set. Please set it to run the agentic system.\")\n",
    "    print(\"   You can set it with: os.environ['OPENAI_API_KEY'] = 'your-key'\")\n",
    "else:\n",
    "    print(\"‚úì OpenAI API key configured\")\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(\"‚úì LLM and embeddings initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset from the use case\n",
    "DATASET = {\n",
    "    \"drivers\": [\n",
    "        {\"driver_id\": \"D001\", \"name\": \"Arjun Kumar\", \"city\": \"Coimbatore\", \"hos_remaining\": 6, \"skill\": \"Reefer\", \"distance_km\": 12, \"on_time\": 92, \"status\": \"AVAILABLE\"},\n",
    "        {\"driver_id\": \"D002\", \"name\": \"Ramesh P\", \"city\": \"Erode\", \"hos_remaining\": 4, \"skill\": \"Flatbed\", \"distance_km\": 50, \"on_time\": 88, \"status\": \"AVAILABLE\"},\n",
    "        {\"driver_id\": \"D003\", \"name\": \"Manoj S\", \"city\": \"Salem\", \"hos_remaining\": 2, \"skill\": \"DryVan\", \"distance_km\": 25, \"on_time\": 79, \"status\": \"BREAK\"},\n",
    "        {\"driver_id\": \"D004\", \"name\": \"Karthik R\", \"city\": \"Coimbatore\", \"hos_remaining\": 8, \"skill\": \"DryVan\", \"distance_km\": 10, \"on_time\": 96, \"status\": \"AVAILABLE\"},\n",
    "        {\"driver_id\": \"D005\", \"name\": \"Siva R\", \"city\": \"Tiruppur\", \"hos_remaining\": 7, \"skill\": \"Reefer\", \"distance_km\": 34, \"on_time\": 90, \"status\": \"AVAILABLE\"},\n",
    "        {\"driver_id\": \"D006\", \"name\": \"Prem K\", \"city\": \"Hosur\", \"hos_remaining\": 3, \"skill\": \"Hazmat\", \"distance_km\": 120, \"on_time\": 87, \"status\": \"AVAILABLE\"},\n",
    "        {\"driver_id\": \"D007\", \"name\": \"Vignesh\", \"city\": \"Cochin\", \"hos_remaining\": 5, \"skill\": \"DryVan\", \"distance_km\": 160, \"on_time\": 95, \"status\": \"AVAILABLE\"},\n",
    "        {\"driver_id\": \"D008\", \"name\": \"Rahul\", \"city\": \"Pollachi\", \"hos_remaining\": 6, \"skill\": \"Flatbed\", \"distance_km\": 22, \"on_time\": 82, \"status\": \"AVAILABLE\"}\n",
    "    ],\n",
    "    \"loads\": [\n",
    "        {\"load_id\": \"L1001\", \"pickup_city\": \"Coimbatore\", \"pickup_time\": \"2025-11-21 09:00\", \"weight_kg\": 1200, \"required_skill\": \"DryVan\", \"delivery_city\": \"Bangalore\", \"distance_km\": 360},\n",
    "        {\"load_id\": \"L1002\", \"pickup_city\": \"Tiruppur\", \"pickup_time\": \"2025-11-21 13:00\", \"weight_kg\": 800, \"required_skill\": \"Reefer\", \"delivery_city\": \"Chennai\", \"distance_km\": 430}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"‚úì Dataset loaded\")\n",
    "display(Markdown(\"### Drivers\"))\n",
    "display(pd.DataFrame(DATASET[\"drivers\"]))\n",
    "display(Markdown(\"### Loads\"))\n",
    "display(pd.DataFrame(DATASET[\"loads\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build FAISS Vector Database\n",
    "\n",
    "Create embeddings and store drivers in FAISS for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_driver_text_representation(driver: Dict) -> str:\n",
    "    \"\"\"Create rich text representation of driver for embedding.\"\"\"\n",
    "    return f\"\"\"\n",
    "    Driver: {driver['name']} (ID: {driver['driver_id']})\n",
    "    Location: {driver['city']}\n",
    "    Status: {driver['status']}\n",
    "    Skills: {driver['skill']} trailer operations\n",
    "    Hours of Service Remaining: {driver['hos_remaining']} hours\n",
    "    Distance to pickup: {driver['distance_km']} km\n",
    "    On-time performance: {driver['on_time']}%\n",
    "    Reliability rating: {'Excellent' if driver['on_time'] >= 90 else 'Good' if driver['on_time'] >= 80 else 'Average'}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def create_load_text_representation(load: Dict) -> str:\n",
    "    \"\"\"Create rich text representation of load for embedding.\"\"\"\n",
    "    return f\"\"\"\n",
    "    Load: {load['load_id']}\n",
    "    Pickup: {load['pickup_city']} at {load['pickup_time']}\n",
    "    Delivery: {load['delivery_city']}\n",
    "    Required trailer type: {load['required_skill']}\n",
    "    Weight: {load['weight_kg']} kg\n",
    "    Distance: {load['distance_km']} km\n",
    "    \"\"\".strip()\n",
    "\n",
    "# Create text representations\n",
    "driver_texts = [create_driver_text_representation(d) for d in DATASET[\"drivers\"]]\n",
    "driver_metadatas = [{**d} for d in DATASET[\"drivers\"]]\n",
    "\n",
    "# Build FAISS vector store\n",
    "print(\"Building FAISS vector database...\")\n",
    "driver_vectorstore = FAISS.from_texts(\n",
    "    texts=driver_texts,\n",
    "    embedding=embeddings,\n",
    "    metadatas=driver_metadatas\n",
    ")\n",
    "\n",
    "print(f\"‚úì FAISS vector database created with {len(driver_texts)} drivers\")\n",
    "print(f\"  Vector dimension: {embeddings.embed_query('test').shape if hasattr(embeddings.embed_query('test'), 'shape') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Tools for Agents\n",
    "\n",
    "Create tools that agents can use to query the vector database and retrieve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_available_drivers(query: str, k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search for available drivers using semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language query describing driver requirements\n",
    "        k: Number of drivers to return (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with matching drivers\n",
    "    \"\"\"\n",
    "    results = driver_vectorstore.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    drivers = []\n",
    "    for doc, score in results:\n",
    "        metadata = doc.metadata\n",
    "        # Only return AVAILABLE drivers\n",
    "        if metadata.get('status') == 'AVAILABLE':\n",
    "            drivers.append({\n",
    "                **metadata,\n",
    "                'similarity_score': float(score),\n",
    "                'description': doc.page_content\n",
    "            })\n",
    "    \n",
    "    return json.dumps(drivers, indent=2)\n",
    "\n",
    "@tool\n",
    "def get_load_details(load_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve detailed information about a specific load.\n",
    "    \n",
    "    Args:\n",
    "        load_id: The load identifier (e.g., 'L1001')\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with load details\n",
    "    \"\"\"\n",
    "    load = next((l for l in DATASET[\"loads\"] if l[\"load_id\"] == load_id), None)\n",
    "    \n",
    "    if not load:\n",
    "        return json.dumps({\"error\": f\"Load {load_id} not found\"})\n",
    "    \n",
    "    return json.dumps(load, indent=2)\n",
    "\n",
    "@tool\n",
    "def get_driver_by_id(driver_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve detailed information about a specific driver.\n",
    "    \n",
    "    Args:\n",
    "        driver_id: The driver identifier (e.g., 'D001')\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with driver details\n",
    "    \"\"\"\n",
    "    driver = next((d for d in DATASET[\"drivers\"] if d[\"driver_id\"] == driver_id), None)\n",
    "    \n",
    "    if not driver:\n",
    "        return json.dumps({\"error\": f\"Driver {driver_id} not found\"})\n",
    "    \n",
    "    return json.dumps(driver, indent=2)\n",
    "\n",
    "@tool\n",
    "def calculate_compatibility_score(driver_id: str, load_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate detailed compatibility score between a driver and load.\n",
    "    \n",
    "    Args:\n",
    "        driver_id: The driver identifier\n",
    "        load_id: The load identifier\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with score breakdown\n",
    "    \"\"\"\n",
    "    driver = next((d for d in DATASET[\"drivers\"] if d[\"driver_id\"] == driver_id), None)\n",
    "    load = next((l for l in DATASET[\"loads\"] if l[\"load_id\"] == load_id), None)\n",
    "    \n",
    "    if not driver or not load:\n",
    "        return json.dumps({\"error\": \"Driver or load not found\"})\n",
    "    \n",
    "    score_breakdown = {\n",
    "        \"driver_id\": driver_id,\n",
    "        \"driver_name\": driver['name'],\n",
    "        \"load_id\": load_id,\n",
    "        \"distance_bonus\": 40 if driver['distance_km'] <= 20 else 0,\n",
    "        \"hos_bonus\": 30 if driver['hos_remaining'] >= 6 else 0,\n",
    "        \"skill_match_bonus\": 20 if driver['skill'] == load['required_skill'] else 0,\n",
    "        \"reliability_score\": round((driver['on_time'] / 10) * 10, 1),\n",
    "    }\n",
    "    \n",
    "    score_breakdown['total_score'] = sum([\n",
    "        score_breakdown['distance_bonus'],\n",
    "        score_breakdown['hos_bonus'],\n",
    "        score_breakdown['skill_match_bonus'],\n",
    "        score_breakdown['reliability_score']\n",
    "    ])\n",
    "    \n",
    "    # Add contextual information\n",
    "    score_breakdown['analysis'] = {\n",
    "        'distance_km': driver['distance_km'],\n",
    "        'hos_remaining': driver['hos_remaining'],\n",
    "        'skill_match': driver['skill'] == load['required_skill'],\n",
    "        'on_time_percentage': driver['on_time'],\n",
    "        'status': driver['status']\n",
    "    }\n",
    "    \n",
    "    return json.dumps(score_breakdown, indent=2)\n",
    "\n",
    "# Create tools list\n",
    "tools = [\n",
    "    search_available_drivers,\n",
    "    get_load_details,\n",
    "    get_driver_by_id,\n",
    "    calculate_compatibility_score\n",
    "]\n",
    "\n",
    "print(\"‚úì Tools created:\")\n",
    "for tool_obj in tools:\n",
    "    print(f\"  - {tool_obj.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgenticDriverAssignmentState(TypedDict):\n",
    "    \"\"\"State for the agentic driver assignment workflow.\"\"\"\n",
    "    \n",
    "    # Input\n",
    "    load_id: str\n",
    "    \n",
    "    # Messages for agent communication\n",
    "    messages: Annotated[List, operator.add]\n",
    "    \n",
    "    # Agent outputs\n",
    "    load_details: Optional[Dict]\n",
    "    candidate_drivers: Optional[List[Dict]]\n",
    "    scored_drivers: Optional[List[Dict]]\n",
    "    final_assignment: Optional[Dict]\n",
    "    reasoning: Annotated[List[str], operator.add]\n",
    "    \n",
    "    # Control flow\n",
    "    next_agent: Optional[str]\n",
    "\n",
    "print(\"‚úì State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Agentic Nodes\n",
    "\n",
    "Each node is a fully autonomous agent with LLM reasoning and tool access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def create_agent_node(agent_name: str, system_prompt: str):\n",
    "    \"\"\"Factory function to create agent nodes with specific roles.\"\"\"\n",
    "    \n",
    "    def agent_node(state: AgenticDriverAssignmentState) -> AgenticDriverAssignmentState:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"[{agent_name}] Starting...\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        messages = state.get(\"messages\", [])\n",
    "        \n",
    "        # Create system message\n",
    "        system_msg = SystemMessage(content=system_prompt)\n",
    "        \n",
    "        # Invoke LLM with tools\n",
    "        response = llm_with_tools.invoke([system_msg] + messages)\n",
    "        \n",
    "        print(f\"\\n[{agent_name}] Response:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Check if agent wants to use tools\n",
    "        if response.tool_calls:\n",
    "            print(f\"\\n[{agent_name}] Using tools:\")\n",
    "            for tool_call in response.tool_calls:\n",
    "                print(f\"  - {tool_call['name']}({tool_call['args']})\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"messages\": [response],\n",
    "            \"reasoning\": [f\"{agent_name}: {response.content}\"]\n",
    "        }\n",
    "    \n",
    "    return agent_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized agent nodes\n",
    "\n",
    "load_analyzer_agent = create_agent_node(\n",
    "    agent_name=\"Load Analyzer\",\n",
    "    system_prompt=\"\"\"\n",
    "    You are the Load Analyzer agent. Your role is to:\n",
    "    1. Retrieve detailed information about the load using available tools\n",
    "    2. Analyze the requirements (pickup location, time, weight, trailer type, distance)\n",
    "    3. Identify key constraints and requirements for driver selection\n",
    "    4. Summarize your findings clearly\n",
    "    \n",
    "    Use the get_load_details tool to retrieve load information.\n",
    "    Be thorough and analytical in your assessment.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "driver_search_agent = create_agent_node(\n",
    "    agent_name=\"Driver Search Specialist\",\n",
    "    system_prompt=\"\"\"\n",
    "    You are the Driver Search Specialist. Your role is to:\n",
    "    1. Use semantic search to find suitable drivers based on load requirements\n",
    "    2. Consider: skill match, location proximity, HOS availability, reliability\n",
    "    3. Retrieve top candidate drivers using the search_available_drivers tool\n",
    "    4. Provide reasoning for why these drivers are good candidates\n",
    "    \n",
    "    Craft intelligent search queries that capture the essence of what makes a driver suitable.\n",
    "    Return at least 3-5 candidate drivers.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "matching_specialist_agent = create_agent_node(\n",
    "    agent_name=\"Matching Specialist\",\n",
    "    system_prompt=\"\"\"\n",
    "    You are the Matching Specialist. Your role is to:\n",
    "    1. Calculate detailed compatibility scores for each candidate driver\n",
    "    2. Use the calculate_compatibility_score tool for each driver\n",
    "    3. Compare and analyze the scores\n",
    "    4. Rank drivers based on total score and provide reasoning\n",
    "    \n",
    "    Consider:\n",
    "    - Distance to pickup (‚â§20km gets bonus)\n",
    "    - Hours of Service remaining (‚â•6 hrs gets bonus)\n",
    "    - Skill match (exact match gets bonus)\n",
    "    - Reliability (on-time percentage)\n",
    "    \n",
    "    Provide a clear ranking with justification.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "assignment_decision_agent = create_agent_node(\n",
    "    agent_name=\"Assignment Decision Maker\",\n",
    "    system_prompt=\"\"\"\n",
    "    You are the Assignment Decision Maker. Your role is to:\n",
    "    1. Review all scored drivers and their compatibility scores\n",
    "    2. Make the final assignment decision\n",
    "    3. Consider not just the highest score, but also:\n",
    "       - Safety and compliance (HOS violations)\n",
    "       - Operational efficiency\n",
    "       - Customer satisfaction\n",
    "    4. Provide clear reasoning for your decision\n",
    "    5. Format the final assignment with all relevant details\n",
    "    \n",
    "    You have the authority to make the final decision. Be confident but explain your reasoning.\n",
    "    Output the assignment in a clear, structured format.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úì Agentic nodes created:\")\n",
    "print(\"  - Load Analyzer\")\n",
    "print(\"  - Driver Search Specialist\")\n",
    "print(\"  - Matching Specialist\")\n",
    "print(\"  - Assignment Decision Maker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tool Execution Node\n",
    "\n",
    "Handle tool calls made by agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "def tool_node(state: AgenticDriverAssignmentState) -> AgenticDriverAssignmentState:\n",
    "    \"\"\"Execute tools requested by agents.\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    if not last_message or not hasattr(last_message, 'tool_calls'):\n",
    "        return state\n",
    "    \n",
    "    tool_calls = last_message.tool_calls\n",
    "    if not tool_calls:\n",
    "        return state\n",
    "    \n",
    "    print(f\"\\n[Tool Execution] Executing {len(tool_calls)} tool call(s)...\")\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        tool_id = tool_call['id']\n",
    "        \n",
    "        # Find and execute the tool\n",
    "        tool_func = next((t for t in tools if t.name == tool_name), None)\n",
    "        if tool_func:\n",
    "            print(f\"  Executing: {tool_name}({tool_args})\")\n",
    "            result = tool_func.invoke(tool_args)\n",
    "            print(f\"  Result preview: {result[:200]}...\" if len(result) > 200 else f\"  Result: {result}\")\n",
    "            \n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=result,\n",
    "                    tool_call_id=tool_id,\n",
    "                    name=tool_name\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": tool_messages\n",
    "    }\n",
    "\n",
    "print(\"‚úì Tool node created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Build the LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgenticDriverAssignmentState) -> Literal[\"tools\", \"continue\"]:\n",
    "    \"\"\"Determine if we should execute tools or continue to next agent.\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    if last_message and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"continue\"\n",
    "\n",
    "# Create the workflow\n",
    "workflow = StateGraph(AgenticDriverAssignmentState)\n",
    "\n",
    "# Add agent nodes\n",
    "workflow.add_node(\"load_analyzer\", load_analyzer_agent)\n",
    "workflow.add_node(\"driver_search\", driver_search_agent)\n",
    "workflow.add_node(\"matching_specialist\", matching_specialist_agent)\n",
    "workflow.add_node(\"assignment_decision\", assignment_decision_agent)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"load_analyzer\")\n",
    "\n",
    "# Add conditional edges for tool calling\n",
    "workflow.add_conditional_edges(\n",
    "    \"load_analyzer\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"continue\": \"driver_search\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"load_analyzer\")  # After tools, return to agent\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"driver_search\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"continue\": \"matching_specialist\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"matching_specialist\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"continue\": \"assignment_decision\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"assignment_decision\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"continue\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úì Agentic workflow compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not visualize graph: {e}\")\n",
    "    print(\"\\nWorkflow structure:\")\n",
    "    print(\"\"\"    \n",
    "    START\n",
    "      ‚Üì\n",
    "    Load Analyzer ‚Üê‚Üí Tools\n",
    "      ‚Üì\n",
    "    Driver Search ‚Üê‚Üí Tools\n",
    "      ‚Üì\n",
    "    Matching Specialist ‚Üê‚Üí Tools\n",
    "      ‚Üì\n",
    "    Assignment Decision ‚Üê‚Üí Tools\n",
    "      ‚Üì\n",
    "    END\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Execute the Agentic Workflow\n",
    "\n",
    "### Test Case 1: Load L1001 (DryVan to Bangalore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ EXECUTING AGENTIC WORKFLOW: Load L1001\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initial state with task description\n",
    "initial_state = {\n",
    "    \"load_id\": \"L1001\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"\"\"\n",
    "        Please assign the best driver for load L1001.\n",
    "        \n",
    "        Requirements:\n",
    "        - Use semantic search to find suitable drivers\n",
    "        - Calculate compatibility scores\n",
    "        - Make an informed decision based on all factors\n",
    "        - Provide clear reasoning for the assignment\n",
    "        \"\"\")\n",
    "    ],\n",
    "    \"load_details\": None,\n",
    "    \"candidate_drivers\": None,\n",
    "    \"scored_drivers\": None,\n",
    "    \"final_assignment\": None,\n",
    "    \"reasoning\": [],\n",
    "    \"next_agent\": None\n",
    "}\n",
    "\n",
    "# Execute workflow\n",
    "try:\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ WORKFLOW COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display reasoning chain\n",
    "    print(\"\\nüìã AGENT REASONING CHAIN:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, reasoning in enumerate(result['reasoning'], 1):\n",
    "        print(f\"\\n{i}. {reasoning}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error executing workflow: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 2: Load L1002 (Reefer to Chennai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ EXECUTING AGENTIC WORKFLOW: Load L1002\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "initial_state_2 = {\n",
    "    \"load_id\": \"L1002\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"\"\"\n",
    "        Please assign the best driver for load L1002.\n",
    "        \n",
    "        Requirements:\n",
    "        - Use semantic search to find suitable drivers\n",
    "        - Calculate compatibility scores\n",
    "        - Make an informed decision based on all factors\n",
    "        - Provide clear reasoning for the assignment\n",
    "        \"\"\")\n",
    "    ],\n",
    "    \"load_details\": None,\n",
    "    \"candidate_drivers\": None,\n",
    "    \"scored_drivers\": None,\n",
    "    \"final_assignment\": None,\n",
    "    \"reasoning\": [],\n",
    "    \"next_agent\": None\n",
    "}\n",
    "\n",
    "try:\n",
    "    result_2 = app.invoke(initial_state_2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ WORKFLOW COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display reasoning chain\n",
    "    print(\"\\nüìã AGENT REASONING CHAIN:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, reasoning in enumerate(result_2['reasoning'], 1):\n",
    "        print(f\"\\n{i}. {reasoning}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error executing workflow: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Advanced: Test Semantic Search Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç Testing FAISS Semantic Search Capabilities\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test different semantic queries\n",
    "test_queries = [\n",
    "    \"Find drivers near Coimbatore with good reliability\",\n",
    "    \"Experienced reefer drivers with high on-time performance\",\n",
    "    \"Drivers with maximum hours of service available\",\n",
    "    \"Closest available flatbed drivers\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    results = driver_vectorstore.similarity_search_with_score(query, k=3)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        metadata = doc.metadata\n",
    "        print(f\"{i}. {metadata['name']} ({metadata['driver_id']}) - Score: {score:.4f}\")\n",
    "        print(f\"   {metadata['city']} | {metadata['skill']} | HOS: {metadata['hos_remaining']}h | On-time: {metadata['on_time']}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Results Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## üéØ Summary: 100% Agentic System Benefits\n",
    "\n",
    "### Key Features Implemented:\n",
    "\n",
    "1. **Fully Autonomous Agents**\n",
    "   - Each agent uses GPT-4 for reasoning\n",
    "   - Agents can call tools independently\n",
    "   - Natural language understanding and generation\n",
    "\n",
    "2. **FAISS Vector Database**\n",
    "   - Semantic search for drivers\n",
    "   - Embedding-based similarity matching\n",
    "   - Efficient retrieval at scale\n",
    "\n",
    "3. **Agent-Tool Integration**\n",
    "   - `search_available_drivers` - Semantic driver search\n",
    "   - `get_load_details` - Load information retrieval\n",
    "   - `calculate_compatibility_score` - Score calculation\n",
    "   - `get_driver_by_id` - Driver detail lookup\n",
    "\n",
    "4. **Multi-Agent Collaboration**\n",
    "   - Load Analyzer ‚Üí Driver Search ‚Üí Matching ‚Üí Assignment\n",
    "   - Each agent specializes in one aspect\n",
    "   - Agents communicate via shared state\n",
    "\n",
    "5. **Explainable AI**\n",
    "   - Every decision is explained\n",
    "   - Reasoning chain is transparent\n",
    "   - Score breakdowns provided\n",
    "\n",
    "### Advantages Over Rule-Based Systems:\n",
    "\n",
    "| Aspect | Rule-Based | Agentic (This System) |\n",
    "|--------|------------|----------------------|\n",
    "| Flexibility | Fixed rules | Adaptive reasoning |\n",
    "| Search | Exact match | Semantic similarity |\n",
    "| Decisions | Algorithmic | LLM-powered |\n",
    "| Explanations | Limited | Natural language |\n",
    "| Edge Cases | Hardcoded | Intelligent handling |\n",
    "| Scalability | Vector DB enables millions of drivers | Limited |\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "Based on the scoring logic:\n",
    "\n",
    "- **Load L1001 (DryVan)**: Driver D004 (Karthik R) - Score: 99.6\n",
    "  - Distance: 10km (‚úì bonus)\n",
    "  - HOS: 8 hrs (‚úì bonus)\n",
    "  - Skill: DryVan (‚úì match)\n",
    "  - On-time: 96% (9.6 points)\n",
    "\n",
    "- **Load L1002 (Reefer)**: Driver D001 (Arjun Kumar) - Score: 99.2\n",
    "  - Distance: 12km (‚úì bonus)\n",
    "  - HOS: 6 hrs (‚úì bonus)\n",
    "  - Skill: Reefer (‚úì match)\n",
    "  - On-time: 92% (9.2 points)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Production Integration**\n",
    "   - Connect to real databases (PostgreSQL, MongoDB)\n",
    "   - Add authentication and authorization\n",
    "   - Implement caching and rate limiting\n",
    "\n",
    "2. **Enhanced Features**\n",
    "   - Real-time driver location tracking\n",
    "   - Weather and traffic integration\n",
    "   - Historical performance analysis\n",
    "   - Predictive analytics for ETA\n",
    "\n",
    "3. **Human-in-the-Loop**\n",
    "   - Add approval workflows\n",
    "   - Feedback mechanism for agent learning\n",
    "   - Override capabilities for dispatchers\n",
    "\n",
    "4. **Monitoring & Analytics**\n",
    "   - Track assignment success rates\n",
    "   - Monitor agent performance\n",
    "   - A/B testing of different strategies\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Interactive: Try Your Own Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_assignment(load_id: str, custom_requirements: str = \"\"):\n",
    "    \"\"\"\n",
    "    Run the agentic workflow with custom requirements.\n",
    "    \n",
    "    Args:\n",
    "        load_id: The load to assign (L1001 or L1002)\n",
    "        custom_requirements: Additional requirements or constraints\n",
    "    \"\"\"\n",
    "    print(f\"\\nüöÄ Custom Assignment Request for {load_id}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"load_id\": load_id,\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=f\"\"\"\n",
    "            Please assign the best driver for load {load_id}.\n",
    "            \n",
    "            {custom_requirements if custom_requirements else 'Use standard criteria for assignment.'}\n",
    "            \n",
    "            Requirements:\n",
    "            - Use semantic search to find suitable drivers\n",
    "            - Calculate compatibility scores\n",
    "            - Make an informed decision\n",
    "            - Provide clear reasoning\n",
    "            \"\"\")\n",
    "        ],\n",
    "        \"load_details\": None,\n",
    "        \"candidate_drivers\": None,\n",
    "        \"scored_drivers\": None,\n",
    "        \"final_assignment\": None,\n",
    "        \"reasoning\": [],\n",
    "        \"next_agent\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        result = app.invoke(initial_state)\n",
    "        print(\"\\n‚úÖ Assignment completed!\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example: Run with custom requirements\n",
    "# result = run_custom_assignment(\n",
    "#     load_id=\"L1001\",\n",
    "#     custom_requirements=\"Prioritize drivers with the highest reliability, even if distance is greater.\"\n",
    "# )\n",
    "\n",
    "print(\"\\nüí° Use the run_custom_assignment() function to test different scenarios!\")\n",
    "print(\"   Example: run_custom_assignment('L1001', 'Prioritize reliability over distance')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
